{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors & Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 5, 9]),\n",
       " tensor([[3, 4, 7],\n",
       "         [9, 8, 3],\n",
       "         [1, 9, 7]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-D tensor \n",
    "a = torch.tensor([4,5,9])\n",
    "# 2-D tensor\n",
    "b = torch.tensor([[3,4,7],\n",
    "                  [9,8,3],\n",
    "                  [1,9,7]])\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) torch.Size([3, 3])\n",
      "torch.Size([3]) torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Shape is an attribute & size is a method \n",
    "print(a.shape,b.shape)\n",
    "print(a.size(),b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3., 7.],\n",
      "        [9., 4., 2.]])\n",
      "torch.float32\n",
      "tensor([[2., 5., 6.],\n",
      "        [2., 8., 7.]], dtype=torch.float64)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# In datatype Float & Double\n",
    "c = torch.FloatTensor([[2,3,7,],\n",
    "                       [9,4,2]])\n",
    "d = torch.DoubleTensor([[2,5,6],\n",
    "                        [2,8,7]])\n",
    "print(c)\n",
    "print(c.dtype)\n",
    "print(d)\n",
    "print(d.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5000) tensor(2.5298, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(c.mean(),d.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: If one of the dimensions is -1, its size can be inferred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3],\n",
      "        [4],\n",
      "        [7],\n",
      "        [9],\n",
      "        [8],\n",
      "        [3],\n",
      "        [1],\n",
      "        [9],\n",
      "        [7]])\n",
      "tensor([[3, 4, 7, 9, 8, 3, 1, 9, 7]])\n",
      "torch.Size([1, 9])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Reshaping \n",
    "print(b.view(-1,1))\n",
    "\n",
    "#Assign b a new shape\n",
    "b = b.view(1,-1)\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(b.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "tensor([[[-0.0582,  0.0535,  0.3627, -0.4277],\n",
      "         [-0.0846, -0.0111,  2.2198, -1.9308],\n",
      "         [-0.5079, -1.7386, -0.1643, -1.1868]],\n",
      "\n",
      "        [[ 1.6911,  0.7561,  0.0533,  1.6616],\n",
      "         [ 0.0407,  1.9136,  0.8203,  1.5195],\n",
      "         [ 0.2678, -2.3893, -1.3377, -1.6780]]])\n",
      "tensor([[-0.0582,  0.0535,  0.3627, -0.4277, -0.0846, -0.0111,  2.2198, -1.9308,\n",
      "         -0.5079, -1.7386, -0.1643, -1.1868],\n",
      "        [ 1.6911,  0.7561,  0.0533,  1.6616,  0.0407,  1.9136,  0.8203,  1.5195,\n",
      "          0.2678, -2.3893, -1.3377, -1.6780]])\n",
      "tensor([[-0.0582,  0.0535,  0.3627, -0.4277, -0.0846, -0.0111,  2.2198, -1.9308,\n",
      "         -0.5079, -1.7386, -0.1643, -1.1868],\n",
      "        [ 1.6911,  0.7561,  0.0533,  1.6616,  0.0407,  1.9136,  0.8203,  1.5195,\n",
      "          0.2678, -2.3893, -1.3377, -1.6780]])\n"
     ]
    }
   ],
   "source": [
    "#Create a 3D Tensor with 2 channels, 3 rows and 4 columns (channles,rows,columns)\n",
    "three_dim = torch.randn(2, 3, 4)\n",
    "print('\\n')\n",
    "print(three_dim)\n",
    "print(three_dim.view(2, 12))  # Reshape to 2 rows, 12 columns\n",
    "print(three_dim.view(2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9815, 0.8231, 0.3390, 0.6735],\n",
      "        [0.7598, 0.8495, 0.7914, 0.9971],\n",
      "        [0.0265, 0.8174, 0.0917, 0.2344],\n",
      "        [0.8165, 0.6241, 0.1597, 0.7280]])\n"
     ]
    }
   ],
   "source": [
    "#Create a matrix with random numbers between 0 and 1\n",
    "r = torch.rand(4,4)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 9, 9],\n",
      "        [7, 6, 8],\n",
      "        [8, 6, 6]])\n"
     ]
    }
   ],
   "source": [
    "#Create a 2-D array (or matrix) of size 3x3 filled with random integers from values between 6 and 9 (exlusive of 10)\n",
    "in_array2 = torch.randint(6,10, (3,3))\n",
    "print(in_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#Get the number of elemetns in in_array\n",
    "print(torch.numel(in_array2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Converting a Torch Tensor to a NumPy Array\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#Converting NumPy Array to Torch Tensor\n",
    "#See how changing the np array changed the Torch Tensor automatically\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Provide Easy switching between CPU and GPU\n",
    "CUDA = torch.cuda.is_available()\n",
    "print(CUDA)\n",
    "if CUDA:\n",
    "    b = b.cuda()\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 1]\n",
      "tensor([2, 3, 4, 1]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "#convert a list to a tensor\n",
    "a = [2,3,4,1]\n",
    "print(a)\n",
    "to_list = torch.tensor(a)\n",
    "print(to_list, to_list.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Concatenation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5716,  0.5063,  0.6617, -0.9603, -0.2902],\n",
      "        [-0.2833, -0.0279,  0.0421, -1.1027,  0.6615]])\n",
      "tensor([[-0.1894, -1.9833, -0.4322, -0.5471,  0.3931],\n",
      "        [ 0.9988, -0.3943,  0.9209,  0.3357,  0.3309],\n",
      "        [ 1.9869, -0.9949, -0.5981, -1.2993,  0.5683]])\n",
      "Column wise \n",
      " tensor([[ 1.5716,  0.5063,  0.6617, -0.9603, -0.2902],\n",
      "        [-0.2833, -0.0279,  0.0421, -1.1027,  0.6615],\n",
      "        [-0.1894, -1.9833, -0.4322, -0.5471,  0.3931],\n",
      "        [ 0.9988, -0.3943,  0.9209,  0.3357,  0.3309],\n",
      "        [ 1.9869, -0.9949, -0.5981, -1.2993,  0.5683]])\n",
      "tensor([[-0.5509,  0.3665, -0.3418],\n",
      "        [ 0.6412, -0.6300,  0.7199]])\n",
      "tensor([[-0.6898, -1.0626, -1.1346, -1.1015, -0.7110],\n",
      "        [ 0.9937, -0.0343,  0.6548, -0.1246,  0.8475]])\n",
      "Row wise \n",
      " tensor([[-0.5509,  0.3665, -0.3418, -0.6898, -1.0626, -1.1346, -1.1015, -0.7110],\n",
      "        [ 0.6412, -0.6300,  0.7199,  0.9937, -0.0343,  0.6548, -0.1246,  0.8475]])\n"
     ]
    }
   ],
   "source": [
    "#Tensor Concatenation \n",
    "first_1 = torch.randn(2, 5)\n",
    "print(first_1)\n",
    "second_1 = torch.randn(3, 5)\n",
    "print(second_1)\n",
    "#Concatenate along the 0 dimension (concatenate rows)\n",
    "con_1 = torch.cat([first_1, second_1])\n",
    "print(\"Column wise \\n\",con_1)\n",
    "first_2 = torch.randn(2, 3)\n",
    "print(first_2)\n",
    "second_2 = torch.randn(2, 5)\n",
    "print(second_2)\n",
    "# Concatenate along the 1 dimension (concatenate columns)\n",
    "con_2 = torch.cat([first_2, second_2], 1)\n",
    "print(\"Row wise \\n\",con_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Dimensions to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]])\n",
      "torch.Size([1, 4])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "#Adds a dimension of 1 along a specified index\n",
    "tensor_1 = torch.tensor([1, 2, 3, 4])\n",
    "tensor_a = torch.unsqueeze(tensor_1, 0)\n",
    "print(tensor_a)\n",
    "print(tensor_a.shape)\n",
    "\n",
    "tensor_b = torch.unsqueeze(tensor_1,1)\n",
    "print(tensor_b)\n",
    "print(tensor_b.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8133, 0.4405, 0.7514, 0.9325],\n",
      "         [0.8841, 0.4036, 0.8466, 0.3881],\n",
      "         [0.6634, 0.9110, 0.5517, 0.1515]],\n",
      "\n",
      "        [[0.5319, 0.5188, 0.5907, 0.9542],\n",
      "         [0.1358, 0.8207, 0.0759, 0.8190],\n",
      "         [0.6612, 0.2079, 0.5134, 0.2246]]])\n",
      "\n",
      "\n",
      "tensor([[0.7514, 0.8466, 0.5517],\n",
      "        [0.5907, 0.0759, 0.5134]])\n",
      "torch.Size([2, 3])\n",
      "\n",
      "\n",
      "tensor([[[0.7514],\n",
      "         [0.8466],\n",
      "         [0.5517]],\n",
      "\n",
      "        [[0.5907],\n",
      "         [0.0759],\n",
      "         [0.5134]]])\n",
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor_2 = torch.rand(2,3,4)\n",
    "print(tensor_2)\n",
    "print('\\n')\n",
    "tensor_c = tensor_2[:,:,2]\n",
    "print(tensor_c)\n",
    "print(tensor_c.shape)\n",
    "print('\\n')\n",
    "tensor_d = torch.unsqueeze(tensor_c,2)\n",
    "print(tensor_d)\n",
    "print(tensor_d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGrad\n",
    "\n",
    "##### If requires_grad=True, the Tensor object keeps track of how it was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  7., 14.], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x00000184CC74C7C0>\n",
      "tensor(31., grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x00000184AF0F95B0>\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([3.,4.,5.],requires_grad=True)\n",
    "b = torch.tensor([7.,3.,9.],requires_grad=True)\n",
    "# a and b have their required_grad set to true, therefore we an compute gradients with respect to them\n",
    "z = a + b\n",
    "print(z)\n",
    "# z knows that is was created as a result of addition of x and y. It knows that it wasn't read in from a file\n",
    "print(z.grad_fn)\n",
    "#And if we go further on this\n",
    "s = z.sum()\n",
    "print(s)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "#Now if we backpropagate on s, we can find the gradients of s with respect to a\n",
    "s.backward()\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# By default, Tensors have `requires_grad=False`\n",
    "x = torch.randn(2, 2)\n",
    "y = torch.randn(2, 2)\n",
    "print(x.requires_grad, y.requires_grad)\n",
    "z = x + y\n",
    "# So you can't backprop through z\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x00000184CC74CCD0>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Another way to set the requires_grad = True is\n",
    "x.requires_grad_()\n",
    "y.requires_grad_()\n",
    "# z contains enough information to compute gradients, as we saw above\n",
    "z = x + y\n",
    "print(z.grad_fn)\n",
    "# If any input to an operation has ``requires_grad=True``, so will the output\n",
    "print(z.requires_grad)\n",
    "# Now z has the computation history that relates itself to x and y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_z :  None\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "new_z = z.detach()\n",
    "print(\"new_z : \",new_z.grad_fn)\n",
    "# z.detach() returns a tensor that shares the same storage as ``z``, but with the computation history forgotten. \n",
    "#It doesn't know anything about how it was computed.In other words, we have broken the Tensor away from its past history\n",
    "\n",
    "#You can also stop autograd from tracking history on Tensors\n",
    "print(x.requires_grad)\n",
    "print((x+10).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x+10).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x00000184AD90B7F0>\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorchWork",
   "language": "python",
   "name": "pytorchwork"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
