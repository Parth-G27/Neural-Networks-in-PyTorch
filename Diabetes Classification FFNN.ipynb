{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn # torch.nn gets all the neural networks classes and functions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset # Used to make PyTorch custom datasets\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Triceps skin fold thickness</th>\n",
       "      <th>2-Hour serum insulin</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>50</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>31</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>32</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>21</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>33</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of times pregnant  Plasma glucose concentration  \\\n",
       "0                         6                           148   \n",
       "1                         1                            85   \n",
       "2                         8                           183   \n",
       "3                         1                            89   \n",
       "4                         0                           137   \n",
       "\n",
       "   Diastolic blood pressure  Triceps skin fold thickness  \\\n",
       "0                        72                           35   \n",
       "1                        66                           29   \n",
       "2                        64                            0   \n",
       "3                        66                           23   \n",
       "4                        40                           35   \n",
       "\n",
       "   2-Hour serum insulin  Body mass index  Age     Class  \n",
       "0                     0             33.6   50  positive  \n",
       "1                     0             26.6   31  negative  \n",
       "2                     0             23.3   32  positive  \n",
       "3                    94             28.1   21  negative  \n",
       "4                   168             43.1   33  positive  "
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Datasets/diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features & Labels Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X : extract data from all rows and features column\n",
    "# y : the label which classifies \n",
    "X = df.iloc[:,0:-1].values\n",
    "y = np.array(df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(y)):\n",
    "    if y[i] == 'positive':\n",
    "        y[i] = 1\n",
    "    if y[i] == 'negative' :\n",
    "        y[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y,dtype= 'float64')\n",
    "type(X),type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features in the range -1 to 1\n",
    "sc = StandardScaler()\n",
    "# x' = x - u / S.D (u = mean)\n",
    "# Fit calculates the mean & S.D for the data and Transform applies that to the data\n",
    "\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function Tensor.type>, <function Tensor.type>)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor(X)\n",
    "y = torch.tensor(y).unsqueeze(1)\n",
    "X.type,y.type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset(X,y)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data to dataloader for batch processing and shuffling \n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                            batch_size =32,\n",
    "                            shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 24 batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {format(len(train_loader))} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,input_features,output_features):\n",
    "        super(Model,self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=input_features,out_features=5)\n",
    "        self.fc2 = nn.Linear(5,4)\n",
    "        self.fc3 = nn.Linear(4,3)\n",
    "        self.fc4 = nn.Linear(3,output_features)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Deep learning with Pytorch\\_pytorch_\\.venv\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "net = Model(7,1)\n",
    "\n",
    "# Creating loss function\n",
    "loss_fn = torch.nn.BCELoss(size_average=True,reduction='mean')\n",
    "\n",
    "# setting up Optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/250 | Loss : 0.5719203352928162 | Accuracy : 0.71875\n",
      " 2/250 | Loss : 0.5396065711975098 | Accuracy : 0.71875\n",
      " 3/250 | Loss : 0.4899923801422119 | Accuracy : 0.71875\n",
      " 4/250 | Loss : 0.4203639030456543 | Accuracy : 0.8125\n",
      " 5/250 | Loss : 0.38801565766334534 | Accuracy : 0.875\n",
      " 6/250 | Loss : 0.39744076132774353 | Accuracy : 0.8125\n",
      " 7/250 | Loss : 0.39927563071250916 | Accuracy : 0.8125\n",
      " 8/250 | Loss : 0.45080679655075073 | Accuracy : 0.71875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/250 | Loss : 0.6585901379585266 | Accuracy : 0.625\n",
      " 10/250 | Loss : 0.4342195987701416 | Accuracy : 0.8125\n",
      " 11/250 | Loss : 0.4841436743736267 | Accuracy : 0.84375\n",
      " 12/250 | Loss : 0.48975569009780884 | Accuracy : 0.75\n",
      " 13/250 | Loss : 0.601681649684906 | Accuracy : 0.6875\n",
      " 14/250 | Loss : 0.465107262134552 | Accuracy : 0.71875\n",
      " 15/250 | Loss : 0.6128020882606506 | Accuracy : 0.6875\n",
      " 16/250 | Loss : 0.3831137418746948 | Accuracy : 0.84375\n",
      " 17/250 | Loss : 0.49536365270614624 | Accuracy : 0.6875\n",
      " 18/250 | Loss : 0.42249807715415955 | Accuracy : 0.78125\n",
      " 19/250 | Loss : 0.41516226530075073 | Accuracy : 0.78125\n",
      " 20/250 | Loss : 0.5079939961433411 | Accuracy : 0.75\n",
      " 21/250 | Loss : 0.5556071400642395 | Accuracy : 0.75\n",
      " 22/250 | Loss : 0.4327622056007385 | Accuracy : 0.78125\n",
      " 23/250 | Loss : 0.46872788667678833 | Accuracy : 0.65625\n",
      " 24/250 | Loss : 0.4893897473812103 | Accuracy : 0.78125\n",
      " 25/250 | Loss : 0.6479378342628479 | Accuracy : 0.625\n",
      " 26/250 | Loss : 0.4416290521621704 | Accuracy : 0.84375\n",
      " 27/250 | Loss : 0.6400161981582642 | Accuracy : 0.65625\n",
      " 28/250 | Loss : 0.47237634658813477 | Accuracy : 0.6875\n",
      " 29/250 | Loss : 0.4318715035915375 | Accuracy : 0.8125\n",
      " 30/250 | Loss : 0.6570777893066406 | Accuracy : 0.65625\n",
      " 31/250 | Loss : 0.42503491044044495 | Accuracy : 0.75\n",
      " 32/250 | Loss : 0.5679548978805542 | Accuracy : 0.78125\n",
      " 33/250 | Loss : 0.421383798122406 | Accuracy : 0.78125\n",
      " 34/250 | Loss : 0.32084566354751587 | Accuracy : 0.8125\n",
      " 35/250 | Loss : 0.3433561623096466 | Accuracy : 0.8125\n",
      " 36/250 | Loss : 0.5682021379470825 | Accuracy : 0.71875\n",
      " 37/250 | Loss : 0.3922208249568939 | Accuracy : 0.78125\n",
      " 38/250 | Loss : 0.34551936388015747 | Accuracy : 0.84375\n",
      " 39/250 | Loss : 0.6700332760810852 | Accuracy : 0.5625\n",
      " 40/250 | Loss : 0.401436984539032 | Accuracy : 0.78125\n",
      " 41/250 | Loss : 0.3570261001586914 | Accuracy : 0.84375\n",
      " 42/250 | Loss : 0.5055390000343323 | Accuracy : 0.71875\n",
      " 43/250 | Loss : 0.3978096544742584 | Accuracy : 0.84375\n",
      " 44/250 | Loss : 0.39816558361053467 | Accuracy : 0.75\n",
      " 45/250 | Loss : 0.445250928401947 | Accuracy : 0.6875\n",
      " 46/250 | Loss : 0.3886256515979767 | Accuracy : 0.84375\n",
      " 47/250 | Loss : 0.6319901943206787 | Accuracy : 0.625\n",
      " 48/250 | Loss : 0.39746522903442383 | Accuracy : 0.75\n",
      " 49/250 | Loss : 0.5952786207199097 | Accuracy : 0.65625\n",
      " 50/250 | Loss : 0.3701106607913971 | Accuracy : 0.90625\n",
      " 51/250 | Loss : 0.3800825774669647 | Accuracy : 0.78125\n",
      " 52/250 | Loss : 0.3786695897579193 | Accuracy : 0.84375\n",
      " 53/250 | Loss : 0.40904831886291504 | Accuracy : 0.78125\n",
      " 54/250 | Loss : 0.3752627670764923 | Accuracy : 0.78125\n",
      " 55/250 | Loss : 0.41165176033973694 | Accuracy : 0.75\n",
      " 56/250 | Loss : 0.3493284583091736 | Accuracy : 0.875\n",
      " 57/250 | Loss : 0.3982656002044678 | Accuracy : 0.75\n",
      " 58/250 | Loss : 0.5348650813102722 | Accuracy : 0.78125\n",
      " 59/250 | Loss : 0.36119478940963745 | Accuracy : 0.8125\n",
      " 60/250 | Loss : 0.48359355330467224 | Accuracy : 0.71875\n",
      " 61/250 | Loss : 0.46361100673675537 | Accuracy : 0.75\n",
      " 62/250 | Loss : 0.4695048928260803 | Accuracy : 0.71875\n",
      " 63/250 | Loss : 0.3686329126358032 | Accuracy : 0.75\n",
      " 64/250 | Loss : 0.26113399863243103 | Accuracy : 0.84375\n",
      " 65/250 | Loss : 0.5898486375808716 | Accuracy : 0.65625\n",
      " 66/250 | Loss : 0.6397379636764526 | Accuracy : 0.6875\n",
      " 67/250 | Loss : 0.3605855107307434 | Accuracy : 0.8125\n",
      " 68/250 | Loss : 0.2839743494987488 | Accuracy : 0.9375\n",
      " 69/250 | Loss : 0.4705717861652374 | Accuracy : 0.84375\n",
      " 70/250 | Loss : 0.4407474994659424 | Accuracy : 0.75\n",
      " 71/250 | Loss : 0.3035564422607422 | Accuracy : 0.9375\n",
      " 72/250 | Loss : 0.3955368399620056 | Accuracy : 0.8125\n",
      " 73/250 | Loss : 0.6033749580383301 | Accuracy : 0.75\n",
      " 74/250 | Loss : 0.37776196002960205 | Accuracy : 0.8125\n",
      " 75/250 | Loss : 0.47460561990737915 | Accuracy : 0.75\n",
      " 76/250 | Loss : 0.33249902725219727 | Accuracy : 0.84375\n",
      " 77/250 | Loss : 0.3057028651237488 | Accuracy : 0.90625\n",
      " 78/250 | Loss : 0.37488263845443726 | Accuracy : 0.90625\n",
      " 79/250 | Loss : 0.8152741193771362 | Accuracy : 0.625\n",
      " 80/250 | Loss : 0.3864580988883972 | Accuracy : 0.90625\n",
      " 81/250 | Loss : 0.39884084463119507 | Accuracy : 0.78125\n",
      " 82/250 | Loss : 0.48499783873558044 | Accuracy : 0.75\n",
      " 83/250 | Loss : 0.4127890169620514 | Accuracy : 0.84375\n",
      " 84/250 | Loss : 0.4313298761844635 | Accuracy : 0.8125\n",
      " 85/250 | Loss : 0.38324078917503357 | Accuracy : 0.875\n",
      " 86/250 | Loss : 0.5432367920875549 | Accuracy : 0.65625\n",
      " 87/250 | Loss : 0.5339508652687073 | Accuracy : 0.6875\n",
      " 88/250 | Loss : 0.7143151760101318 | Accuracy : 0.625\n",
      " 89/250 | Loss : 0.3217712640762329 | Accuracy : 0.8125\n",
      " 90/250 | Loss : 0.368198961019516 | Accuracy : 0.78125\n",
      " 91/250 | Loss : 0.29051244258880615 | Accuracy : 0.84375\n",
      " 92/250 | Loss : 0.4436662197113037 | Accuracy : 0.75\n",
      " 93/250 | Loss : 0.4368082582950592 | Accuracy : 0.8125\n",
      " 94/250 | Loss : 0.4601322114467621 | Accuracy : 0.78125\n",
      " 95/250 | Loss : 0.4126679003238678 | Accuracy : 0.8125\n",
      " 96/250 | Loss : 0.39220690727233887 | Accuracy : 0.8125\n",
      " 97/250 | Loss : 0.49708548188209534 | Accuracy : 0.71875\n",
      " 98/250 | Loss : 0.2592281401157379 | Accuracy : 0.90625\n",
      " 99/250 | Loss : 0.3068041205406189 | Accuracy : 0.84375\n",
      " 100/250 | Loss : 0.546524703502655 | Accuracy : 0.65625\n",
      " 101/250 | Loss : 0.33300289511680603 | Accuracy : 0.875\n",
      " 102/250 | Loss : 0.43130674958229065 | Accuracy : 0.75\n",
      " 103/250 | Loss : 0.5123051404953003 | Accuracy : 0.78125\n",
      " 104/250 | Loss : 0.4176294505596161 | Accuracy : 0.8125\n",
      " 105/250 | Loss : 0.33487826585769653 | Accuracy : 0.84375\n",
      " 106/250 | Loss : 0.520351767539978 | Accuracy : 0.71875\n",
      " 107/250 | Loss : 0.5012365579605103 | Accuracy : 0.75\n",
      " 108/250 | Loss : 0.28658270835876465 | Accuracy : 0.875\n",
      " 109/250 | Loss : 0.47710704803466797 | Accuracy : 0.75\n",
      " 110/250 | Loss : 0.4725461006164551 | Accuracy : 0.71875\n",
      " 111/250 | Loss : 0.27500587701797485 | Accuracy : 0.90625\n",
      " 112/250 | Loss : 0.3451729714870453 | Accuracy : 0.875\n",
      " 113/250 | Loss : 0.4233328700065613 | Accuracy : 0.78125\n",
      " 114/250 | Loss : 0.28356337547302246 | Accuracy : 0.90625\n",
      " 115/250 | Loss : 0.31517261266708374 | Accuracy : 0.9375\n",
      " 116/250 | Loss : 0.46681684255599976 | Accuracy : 0.78125\n",
      " 117/250 | Loss : 0.5123701691627502 | Accuracy : 0.71875\n",
      " 118/250 | Loss : 0.368157297372818 | Accuracy : 0.84375\n",
      " 119/250 | Loss : 0.4237636923789978 | Accuracy : 0.78125\n",
      " 120/250 | Loss : 0.4962500333786011 | Accuracy : 0.75\n",
      " 121/250 | Loss : 0.6037853956222534 | Accuracy : 0.71875\n",
      " 122/250 | Loss : 0.5431466698646545 | Accuracy : 0.8125\n",
      " 123/250 | Loss : 0.3104661703109741 | Accuracy : 0.84375\n",
      " 124/250 | Loss : 0.5293647646903992 | Accuracy : 0.6875\n",
      " 125/250 | Loss : 0.49101975560188293 | Accuracy : 0.8125\n",
      " 126/250 | Loss : 0.37583979964256287 | Accuracy : 0.78125\n",
      " 127/250 | Loss : 0.37409457564353943 | Accuracy : 0.75\n",
      " 128/250 | Loss : 0.27555036544799805 | Accuracy : 0.90625\n",
      " 129/250 | Loss : 0.5443307161331177 | Accuracy : 0.78125\n",
      " 130/250 | Loss : 0.4423125088214874 | Accuracy : 0.78125\n",
      " 131/250 | Loss : 0.361333966255188 | Accuracy : 0.84375\n",
      " 132/250 | Loss : 0.35888248682022095 | Accuracy : 0.84375\n",
      " 133/250 | Loss : 0.461395263671875 | Accuracy : 0.71875\n",
      " 134/250 | Loss : 0.4777238368988037 | Accuracy : 0.75\n",
      " 135/250 | Loss : 0.39959490299224854 | Accuracy : 0.8125\n",
      " 136/250 | Loss : 0.28494778275489807 | Accuracy : 0.9375\n",
      " 137/250 | Loss : 0.3570743203163147 | Accuracy : 0.8125\n",
      " 138/250 | Loss : 0.4462928771972656 | Accuracy : 0.78125\n",
      " 139/250 | Loss : 0.2937576472759247 | Accuracy : 0.84375\n",
      " 140/250 | Loss : 0.31788140535354614 | Accuracy : 0.875\n",
      " 141/250 | Loss : 0.3463679552078247 | Accuracy : 0.8125\n",
      " 142/250 | Loss : 0.4525953233242035 | Accuracy : 0.78125\n",
      " 143/250 | Loss : 0.3535322844982147 | Accuracy : 0.84375\n",
      " 144/250 | Loss : 0.3143613040447235 | Accuracy : 0.90625\n",
      " 145/250 | Loss : 0.27855822443962097 | Accuracy : 0.90625\n",
      " 146/250 | Loss : 0.40015432238578796 | Accuracy : 0.75\n",
      " 147/250 | Loss : 0.3678857684135437 | Accuracy : 0.8125\n",
      " 148/250 | Loss : 0.5611305236816406 | Accuracy : 0.6875\n",
      " 149/250 | Loss : 0.5801060199737549 | Accuracy : 0.75\n",
      " 150/250 | Loss : 0.3930509686470032 | Accuracy : 0.8125\n",
      " 151/250 | Loss : 0.48008692264556885 | Accuracy : 0.90625\n",
      " 152/250 | Loss : 0.47108912467956543 | Accuracy : 0.8125\n",
      " 153/250 | Loss : 0.32612404227256775 | Accuracy : 0.84375\n",
      " 154/250 | Loss : 0.483999103307724 | Accuracy : 0.75\n",
      " 155/250 | Loss : 0.47156837582588196 | Accuracy : 0.71875\n",
      " 156/250 | Loss : 0.3530505895614624 | Accuracy : 0.8125\n",
      " 157/250 | Loss : 0.40937843918800354 | Accuracy : 0.8125\n",
      " 158/250 | Loss : 0.5788300037384033 | Accuracy : 0.65625\n",
      " 159/250 | Loss : 0.2358681857585907 | Accuracy : 0.90625\n",
      " 160/250 | Loss : 0.39551833271980286 | Accuracy : 0.84375\n",
      " 161/250 | Loss : 0.5832021236419678 | Accuracy : 0.6875\n",
      " 162/250 | Loss : 0.47822099924087524 | Accuracy : 0.71875\n",
      " 163/250 | Loss : 0.288987934589386 | Accuracy : 0.84375\n",
      " 164/250 | Loss : 0.3562065362930298 | Accuracy : 0.8125\n",
      " 165/250 | Loss : 0.4183482229709625 | Accuracy : 0.75\n",
      " 166/250 | Loss : 0.4212722182273865 | Accuracy : 0.78125\n",
      " 167/250 | Loss : 0.4669142961502075 | Accuracy : 0.71875\n",
      " 168/250 | Loss : 0.3759099245071411 | Accuracy : 0.8125\n",
      " 169/250 | Loss : 0.40245428681373596 | Accuracy : 0.78125\n",
      " 170/250 | Loss : 0.24405726790428162 | Accuracy : 0.9375\n",
      " 171/250 | Loss : 0.45137834548950195 | Accuracy : 0.71875\n",
      " 172/250 | Loss : 0.31984972953796387 | Accuracy : 0.90625\n",
      " 173/250 | Loss : 0.28850528597831726 | Accuracy : 0.90625\n",
      " 174/250 | Loss : 0.41769230365753174 | Accuracy : 0.78125\n",
      " 175/250 | Loss : 0.4339228868484497 | Accuracy : 0.8125\n",
      " 176/250 | Loss : 0.27826040983200073 | Accuracy : 0.84375\n",
      " 177/250 | Loss : 0.36018499732017517 | Accuracy : 0.8125\n",
      " 178/250 | Loss : 0.26538974046707153 | Accuracy : 0.90625\n",
      " 179/250 | Loss : 0.31635090708732605 | Accuracy : 0.9375\n",
      " 180/250 | Loss : 0.47378233075141907 | Accuracy : 0.78125\n",
      " 181/250 | Loss : 0.39911404252052307 | Accuracy : 0.8125\n",
      " 182/250 | Loss : 0.33301255106925964 | Accuracy : 0.875\n",
      " 183/250 | Loss : 0.5218623280525208 | Accuracy : 0.8125\n",
      " 184/250 | Loss : 0.3822976052761078 | Accuracy : 0.8125\n",
      " 185/250 | Loss : 0.3499101996421814 | Accuracy : 0.84375\n",
      " 186/250 | Loss : 0.4843527674674988 | Accuracy : 0.71875\n",
      " 187/250 | Loss : 0.43776386976242065 | Accuracy : 0.78125\n",
      " 188/250 | Loss : 0.37737107276916504 | Accuracy : 0.78125\n",
      " 189/250 | Loss : 0.4110664427280426 | Accuracy : 0.78125\n",
      " 190/250 | Loss : 0.5138781070709229 | Accuracy : 0.71875\n",
      " 191/250 | Loss : 0.27210670709609985 | Accuracy : 0.875\n",
      " 192/250 | Loss : 0.2408829629421234 | Accuracy : 0.90625\n",
      " 193/250 | Loss : 0.43595877289772034 | Accuracy : 0.78125\n",
      " 194/250 | Loss : 0.18963545560836792 | Accuracy : 0.9375\n",
      " 195/250 | Loss : 0.3500595688819885 | Accuracy : 0.84375\n",
      " 196/250 | Loss : 0.3722195029258728 | Accuracy : 0.8125\n",
      " 197/250 | Loss : 0.2673141062259674 | Accuracy : 0.90625\n",
      " 198/250 | Loss : 0.4604737162590027 | Accuracy : 0.75\n",
      " 199/250 | Loss : 0.3012712299823761 | Accuracy : 0.84375\n",
      " 200/250 | Loss : 0.35033929347991943 | Accuracy : 0.75\n",
      " 201/250 | Loss : 0.4050785303115845 | Accuracy : 0.8125\n",
      " 202/250 | Loss : 0.34798794984817505 | Accuracy : 0.84375\n",
      " 203/250 | Loss : 0.2953265607357025 | Accuracy : 0.875\n",
      " 204/250 | Loss : 0.5141482353210449 | Accuracy : 0.78125\n",
      " 205/250 | Loss : 0.3479018211364746 | Accuracy : 0.90625\n",
      " 206/250 | Loss : 0.3371693789958954 | Accuracy : 0.875\n",
      " 207/250 | Loss : 0.5397035479545593 | Accuracy : 0.625\n",
      " 208/250 | Loss : 0.5477190017700195 | Accuracy : 0.6875\n",
      " 209/250 | Loss : 0.37127119302749634 | Accuracy : 0.8125\n",
      " 210/250 | Loss : 0.32516202330589294 | Accuracy : 0.84375\n",
      " 211/250 | Loss : 0.46207088232040405 | Accuracy : 0.78125\n",
      " 212/250 | Loss : 0.5398485064506531 | Accuracy : 0.75\n",
      " 213/250 | Loss : 0.3162764310836792 | Accuracy : 0.84375\n",
      " 214/250 | Loss : 0.3347058594226837 | Accuracy : 0.84375\n",
      " 215/250 | Loss : 0.22680683434009552 | Accuracy : 0.96875\n",
      " 216/250 | Loss : 0.36560165882110596 | Accuracy : 0.84375\n",
      " 217/250 | Loss : 0.5186489820480347 | Accuracy : 0.78125\n",
      " 218/250 | Loss : 0.3861226737499237 | Accuracy : 0.84375\n",
      " 219/250 | Loss : 0.5362483263015747 | Accuracy : 0.75\n",
      " 220/250 | Loss : 0.5163120031356812 | Accuracy : 0.75\n",
      " 221/250 | Loss : 0.35118094086647034 | Accuracy : 0.8125\n",
      " 222/250 | Loss : 0.4072009027004242 | Accuracy : 0.84375\n",
      " 223/250 | Loss : 0.4854322373867035 | Accuracy : 0.78125\n",
      " 224/250 | Loss : 0.34572550654411316 | Accuracy : 0.84375\n",
      " 225/250 | Loss : 0.432964026927948 | Accuracy : 0.6875\n",
      " 226/250 | Loss : 0.4084829092025757 | Accuracy : 0.84375\n",
      " 227/250 | Loss : 0.306755006313324 | Accuracy : 0.875\n",
      " 228/250 | Loss : 0.41060319542884827 | Accuracy : 0.8125\n",
      " 229/250 | Loss : 0.3731500804424286 | Accuracy : 0.84375\n",
      " 230/250 | Loss : 0.3841383159160614 | Accuracy : 0.78125\n",
      " 231/250 | Loss : 0.3033396303653717 | Accuracy : 0.90625\n",
      " 232/250 | Loss : 0.2595285177230835 | Accuracy : 0.90625\n",
      " 233/250 | Loss : 0.3603854477405548 | Accuracy : 0.84375\n",
      " 234/250 | Loss : 0.5273721814155579 | Accuracy : 0.71875\n",
      " 235/250 | Loss : 0.41065260767936707 | Accuracy : 0.8125\n",
      " 236/250 | Loss : 0.32035475969314575 | Accuracy : 0.84375\n",
      " 237/250 | Loss : 0.289131224155426 | Accuracy : 0.84375\n",
      " 238/250 | Loss : 0.3621866703033447 | Accuracy : 0.875\n",
      " 239/250 | Loss : 0.28980234265327454 | Accuracy : 0.84375\n",
      " 240/250 | Loss : 0.22561991214752197 | Accuracy : 0.96875\n",
      " 241/250 | Loss : 0.4951181411743164 | Accuracy : 0.65625\n",
      " 242/250 | Loss : 0.4470897614955902 | Accuracy : 0.78125\n",
      " 243/250 | Loss : 0.5395073890686035 | Accuracy : 0.6875\n",
      " 244/250 | Loss : 0.45155662298202515 | Accuracy : 0.75\n",
      " 245/250 | Loss : 0.34895139932632446 | Accuracy : 0.84375\n",
      " 246/250 | Loss : 0.4469437301158905 | Accuracy : 0.75\n",
      " 247/250 | Loss : 0.4724952280521393 | Accuracy : 0.75\n",
      " 248/250 | Loss : 0.4011451005935669 | Accuracy : 0.84375\n",
      " 249/250 | Loss : 0.4689679741859436 | Accuracy : 0.8125\n",
      " 250/250 | Loss : 0.29542452096939087 | Accuracy : 0.84375\n"
     ]
    }
   ],
   "source": [
    "epochs = 250\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for inputs,labels in train_loader:\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "\n",
    "        # Forwards propagation\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_fn(outputs,labels)\n",
    "\n",
    "        # Clear the gradient buffer \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backpropagation : calculating gradients \n",
    "        loss.backward()\n",
    "\n",
    "        # Backpropagation : Updating weights\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculating accuracy \n",
    "    output = (outputs>0.5).float()\n",
    "    acc = (output==labels).float().mean()\n",
    "\n",
    "    print(f\" {epoch+1}/{epochs} | Loss : {loss} | Accuracy : {acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training accuracy \n",
    "with torch.inference_mode():\n",
    "    preds = net(X.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]])"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = preds>0.5\n",
    "preds == y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8346354166666666"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_final = accuracy_score(y.float(),preds)\n",
    "accuracy_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorchWork",
   "language": "python",
   "name": "pytorchwork"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
